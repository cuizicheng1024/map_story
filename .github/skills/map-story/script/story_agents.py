"""
èŒè´£ï¼šè´Ÿè´£â€œæ•…äº‹ç”Ÿæˆâ€ï¼ˆè°ƒç”¨ LLMï¼‰ï¼Œä¸åŒ…å«åœ°å›¾æˆ–è·ç¦»ç›¸å…³é€»è¾‘ã€‚
æç¤ºè¯ä» docs/ ç›®å½•åŠ è½½ï¼Œä¾¿äºé›†ä¸­ç®¡ç†ä¸è°ƒä¼˜ã€‚
"""
import argparse
import json
import os
import re
from typing import Dict, List, Optional

from dotenv import load_dotenv
from openai import OpenAI


def _project_root() -> str:
    return os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "..", ".."))


local_env = os.path.join(os.path.dirname(__file__), ".env")
load_dotenv(dotenv_path=local_env)
load_dotenv(dotenv_path=os.path.join(_project_root(), ".env"))

_MAX_TEXT_LEN = 200


def _validate_person(text: object) -> Optional[str]:
    if not isinstance(text, str):
        return "è¾“å…¥å¿…é¡»æ˜¯å­—ç¬¦ä¸²"
    cleaned = text.strip()
    if not cleaned:
        return "è¾“å…¥ä¸èƒ½ä¸ºç©º"
    if len(cleaned) > _MAX_TEXT_LEN:
        return f"è¾“å…¥è¿‡é•¿ï¼ˆæœ€å¤š {_MAX_TEXT_LEN} å­—ç¬¦ï¼‰"
    return None


class StoryAgentLLM:
    """
    ä¸»è¦èŒè´£ï¼š
    - ç»Ÿä¸€ç®¡ç†æ¨¡å‹ IDã€API Keyã€Base URL ç­‰åŸºç¡€é…ç½®
    - å¯¹å…¼å®¹ OpenAI æ¥å£çš„æœåŠ¡å‘èµ·å¯¹è¯è¯·æ±‚
    - é»˜è®¤ä½¿ç”¨æµå¼ï¼ˆstream=Trueï¼‰æ–¹å¼é€å—æ‰“å°æ¨¡å‹å“åº”
    """
    def __init__(
        self,
        model: Optional[str] = None,
        apiKey: Optional[str] = None,
        baseUrl: Optional[str] = None,
        timeout: Optional[int] = None,
        event_callback: Optional[callable] = None,
    ):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚

        ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼›å¦‚æœæŸä¸ªå‚æ•°ä¸º Noneï¼Œåˆ™ä¼šå›é€€åˆ°ç¯å¢ƒå˜é‡ï¼š
        - LLM_MODEL_ID  -> æ¨¡å‹ ID
        - LLM_API_KEY   -> API Key
        - LLM_BASE_URL  -> æœåŠ¡åœ°å€ï¼ˆå…¼å®¹ OpenAI åè®®çš„ç½‘å…³ï¼‰
        - LLM_TIMEOUT   -> è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        self.event_callback = event_callback
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT", "60"))

        if not self.model or not apiKey or not baseUrl:
            raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚")

        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def _emit(self, message: str) -> None:
        if not self.event_callback:
            return
        try:
            self.event_callback(message)
        except Exception:
            pass

    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> Optional[str]:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œâ€œæ€è€ƒâ€ï¼Œå¹¶ä»¥æµå¼æ–¹å¼è¾“å‡ºä¸è¿”å›å®Œæ•´ç»“æœã€‚

        å‚æ•°ï¼š
        - messages: èŠå¤©å†å²ï¼Œæ ¼å¼ä¸ OpenAI ChatCompletion æ¥å£ä¸€è‡´
        - temperature: é‡‡æ ·æ¸©åº¦ï¼Œæ•°å€¼è¶Šå¤§å›ç­”è¶Šå‘æ•£ï¼Œé»˜è®¤ 0ï¼ˆæ›´ç¨³å®šï¼‰

        è¿”å›ï¼š
        - æ¨¡å‹å®Œæ•´è¾“å‡ºçš„å­—ç¬¦ä¸²ï¼›å¦‚æœå‘ç”Ÿé”™è¯¯åˆ™è¿”å› None
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        self._emit(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )
            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected: List[str] = []
            for chunk in response:
                if not getattr(chunk, "choices", None):
                    continue
                delta = chunk.choices[0].delta
                content = getattr(delta, "content", None) or ""
                if not content:
                    continue
                print(content, end="", flush=True)
                collected.append(content)
            print()
            result = "".join(collected)
            if result:
                self._emit(f"âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ: {result}")
            else:
                self._emit("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ")
            return result

        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self._emit(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None


def _read_prompt(relpath: str) -> str:
    """
    è¯»å– docs/ ç›®å½•ä¸‹çš„æç¤ºè¯æ–‡ä»¶å†…å®¹ã€‚
    """
    root = os.path.dirname(os.path.abspath(__file__))
    with open(os.path.join(root, "..", "docs", relpath), "r", encoding="utf-8") as f:
        return f.read()


def generate_historical_markdown(llm: "StoryAgentLLM", person: str) -> Optional[str]:
    """
    ç”ŸæˆæŒ‡å®šäººç‰©çš„ç”Ÿå¹³ Markdownã€‚
    """
    system_prompt = _read_prompt("story_system_prompt.md")
    user_prompt = f"è¯·æ•´ç†å†å²äººç‰©ã€Œ{person}ã€çš„ç”Ÿå¹³ä¿¡æ¯ï¼Œå¹¶æŒ‰è¦æ±‚è¾“å‡ºã€‚"
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    return llm.think(messages, temperature=0.1)


def extract_historical_figures(llm: "StoryAgentLLM", text: str) -> List[str]:
    """
    ä»è¾“å…¥æ–‡æœ¬ä¸­æŠ½å–å†å²äººç‰©åç§°åˆ—è¡¨ã€‚
    """
    if not isinstance(text, str):
        return []
    sys_prompt = _read_prompt("extract_names_prompt.md")
    messages = [
        {"role": "system", "content": sys_prompt},
        {"role": "user", "content": text},
    ]
    raw = llm.think(messages, temperature=0)
    if not raw:
        return []
    try:
        data = json.loads(raw.strip())
        if isinstance(data, list):
            names = [str(x).strip() for x in data if str(x).strip()]
            return list(dict.fromkeys(names))
    except Exception:
        pass
    cleaned = raw.strip()
    return [cleaned] if cleaned else []


def save_markdown(person: str, content: str) -> str:
    """
    å°†äººç‰©ç”Ÿå¹³ Markdown å†™å…¥ story/ ç›®å½•å¹¶è¿”å›æ–‡ä»¶è·¯å¾„ã€‚
    """
    root = _project_root()
    folder = os.path.join(root, "story")
    os.makedirs(folder, exist_ok=True)
    safe = re.sub(r'[\\\\/:*?"<>|]', "_", str(person or "")).strip()
    if not safe:
        safe = "æœªå‘½åäººç‰©"
    path = os.path.join(folder, f"{safe}.md")
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return path


def run_interactive(llm: "StoryAgentLLM") -> None:
    """
    äº¤äº’å¼è¾“å…¥äººç‰©å¹¶ç”Ÿæˆ Markdownã€‚
    """
    while True:
        try:
            name = input("è¯·è¾“å…¥å†å²äººç‰©ï¼ˆq/quit/exit é€€å‡ºï¼‰ï¼š").strip()
        except EOFError:
            break
        if not name:
            continue
        err = _validate_person(name)
        if err:
            print(err)
            continue
        if name.lower() in {"q", "quit", "exit"}:
            print("å·²é€€å‡ºã€‚")
            break
        targets = extract_historical_figures(llm, name)
        if not targets:
            print("æœªè¯†åˆ«åˆ°å†å²äººç‰©ï¼Œè¯·é‡è¯•ã€‚")
            continue
        for person in targets:
            md = generate_historical_markdown(llm, person)
            if md:
                saved = save_markdown(person, md)
                print(f"å·²ç”Ÿæˆï¼š{saved}")
                print(md)
            else:
                print(f"æœªå–å¾—ã€Œ{person}ã€ç»“æœã€‚")


def main():
    parser = argparse.ArgumentParser(
        description="åŸºäºç¯å¢ƒå˜é‡é…ç½®çš„ LLMï¼Œç”Ÿæˆå†å²äººç‰©çš„ Markdown ç”Ÿå¹³ä¿¡æ¯ã€‚"
    )
    parser.add_argument(
        "-p", "--person", help="å†å²äººç‰©å§“åï¼Œä¾‹å¦‚ï¼šæç™½ã€æœç”«ã€è¯¸è‘›äº®", required=False
    )
    args = parser.parse_args()

    if args.person:
        try:
            err = _validate_person(args.person)
            if err:
                print(err)
                return
            client = StoryAgentLLM()
            targets = extract_historical_figures(client, args.person)
            if not targets:
                print("æœªè¯†åˆ«åˆ°å†å²äººç‰©ã€‚")
                return
            for person in targets:
                md = generate_historical_markdown(client, person)
                if md:
                    saved = save_markdown(person, md)
                    print(f"å·²ç”Ÿæˆï¼š{saved}")
                    print(md)
        except ValueError as e:
            print(e)
        return

    try:
        client = StoryAgentLLM()
        run_interactive(client)
    except ValueError as e:
        print(e)


if __name__ == "__main__":
    main()
